import { NextRequest, NextResponse } from 'next/server';

const HF_API_URL = 'https://api-inference.huggingface.co/models/seungheondoh/lp-music-caps';

interface HuggingFaceResponse {
  generated_text?: string;
  error?: string;
}

/**
 * Call Hugging Face API for music captioning
 */
async function callHuggingFaceAPI(audioBuffer: ArrayBuffer): Promise<string | null> {
  try {
    console.log('üéµ Calling Hugging Face LP-MusicCaps API...');
    
    if (!process.env.HUGGINGFACE_API_TOKEN) {
      throw new Error('HUGGINGFACE_API_TOKEN not configured');
    }

    const response = await fetch(HF_API_URL, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.HUGGINGFACE_API_TOKEN}`,
        'Content-Type': 'audio/wav',
      },
      body: audioBuffer,
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå Hugging Face API error:', response.status, response.statusText, errorText);
      
      // Handle specific errors
      if (response.status === 404) {
        throw new Error('LP-MusicCaps model is not available through Hugging Face Inference API. The model exists but is not deployed by any inference providers.');
      }
      if (response.status === 503) {
        throw new Error('Model is loading, please try again in a few minutes');
      }
      if (response.status === 401) {
        throw new Error('Invalid Hugging Face API token');
      }
      
      throw new Error(`API request failed: ${response.status} ${response.statusText}`);
    }

    const result: HuggingFaceResponse = await response.json();
    console.log('‚úÖ Hugging Face API response received');

    if (result.error) {
      throw new Error(result.error);
    }

    if (result.generated_text) {
      console.log('‚úÖ Music caption generated successfully');
      return result.generated_text;
    }

    console.warn('‚ö†Ô∏è No generated text in response');
    return null;

  } catch (error: any) {
    console.error('‚ùå Hugging Face API call failed:', error);
    throw error;
  }
}

/**
 * Convert audio file to WAV format for the model
 */
async function convertToWav(audioFile: File): Promise<ArrayBuffer> {
  try {
    console.log('üîÑ Converting audio to WAV format...');
    
    // For now, we'll send the file as-is and let HF handle the conversion
    // The model should accept various audio formats
    const arrayBuffer = await audioFile.arrayBuffer();
    
    console.log('‚úÖ Audio buffer prepared:', arrayBuffer.byteLength, 'bytes');
    return arrayBuffer;
    
  } catch (error) {
    console.error('‚ùå Audio conversion failed:', error);
    throw new Error('Failed to process audio file');
  }
}

/**
 * Format the AI response into structured music notes
 */
function formatMusicNotes(caption: string, metadata: { duration?: number, size?: number }): string {
  const notes = `üéµ **Music AI Analysis**

**Description:**
${caption}

**Technical Info:**
${metadata.duration ? `Duration: ${Math.round(metadata.duration)}s` : ''}
${metadata.size ? `File Size: ${Math.round(metadata.size / 1024 / 1024 * 100) / 100}MB` : ''}

*Generated by LP-MusicCaps (Hugging Face)*`;

  return notes;
}

export async function POST(request: NextRequest) {
  console.log('üéµ Hugging Face music analysis API called');
  
  try {
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      console.error('‚ùå No audio file provided');
      return NextResponse.json({ error: 'No audio file provided' }, { status: 400 });
    }

    console.log('üìÅ Processing audio file:', audioFile.name, `(${audioFile.size} bytes, ${audioFile.type})`);

    // Validate file type
    const allowedTypes = ['audio/mp3', 'audio/wav', 'audio/ogg', 'audio/m4a', 'audio/aac', 'audio/mpeg'];
    if (!allowedTypes.includes(audioFile.type)) {
      console.error('‚ùå Invalid file type:', audioFile.type);
      return NextResponse.json({ error: `Invalid file type: ${audioFile.type}` }, { status: 400 });
    }

    // Validate file size (limit to 25MB for HF API)
    const maxSize = 25 * 1024 * 1024; // 25MB
    if (audioFile.size > maxSize) {
      console.error('‚ùå File too large for AI analysis:', audioFile.size);
      return NextResponse.json({ 
        error: 'File too large for AI analysis (max 25MB)' 
      }, { status: 400 });
    }

    // Convert audio to appropriate format
    const audioBuffer = await convertToWav(audioFile);
    
    // Call Hugging Face API
    const caption = await callHuggingFaceAPI(audioBuffer);
    
    if (!caption) {
      return NextResponse.json({
        success: false,
        error: 'No caption generated by the model'
      });
    }

    // Format the response
    const musicNotes = formatMusicNotes(caption, {
      duration: 0, // We don't have duration info from buffer
      size: audioFile.size
    });

    console.log('‚úÖ Music analysis completed successfully');
    
    return NextResponse.json({
      success: true,
      musicNotes,
      rawCaption: caption,
      model: 'seungheondoh/lp-music-caps',
      provider: 'Hugging Face'
    });

  } catch (error: any) {
    console.error('‚ùå Music analysis error:', error);
    
    return NextResponse.json({
      success: false,
      error: error.message || 'Music analysis failed',
      details: error.stack
    }, { status: 500 });
  }
}

/**
 * GET endpoint for API information
 */
export async function GET() {
  return NextResponse.json({
    model: 'seungheondoh/lp-music-caps',
    provider: 'Hugging Face',
    description: 'LLM-Based Pseudo Music Captioning',
    maxFileSize: '25MB',
    supportedFormats: ['MP3', 'WAV', 'OGG', 'M4A', 'AAC'],
    endpoint: '/api/ai/huggingface-music'
  });
}